{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 \n",
    "import os\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import *\n",
    "from keras.utils.vis_utils import plot_model\n",
    "kernel_init = keras.initializers.glorot_uniform()\n",
    "bias_init = keras.initializers.Constant(value=0.2)\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "def data_loader():\n",
    "    \n",
    "    # Load dataset file\n",
    "    data_frame = pd.read_csv('training.csv')\n",
    "    \n",
    "    data_frame['Image'] = data_frame['Image'].apply(lambda i: np.fromstring(i, sep=' '))\n",
    "    data_frame = data_frame.dropna()  # Get only the data with 15 keypoints\n",
    "   \n",
    "    # Extract Images pixel values\n",
    "    imgs_array = np.vstack(data_frame['Image'].values)/ 255.0\n",
    "    imgs_array = imgs_array.astype(np.float32)    # Normalize, target values to (0, 1)\n",
    "    imgs_array = imgs_array.reshape(-1, 96, 96, 1)\n",
    "        \n",
    "    # Extract labels (key point cords)\n",
    "    labels_array = data_frame[data_frame.columns[:-1]].values\n",
    "    labels_array = (labels_array - 48) / 48    # Normalize, traget cordinates to (-1, 1)\n",
    "    labels_array = labels_array.astype(np.float32) \n",
    "    \n",
    "    # shuffle the train data\n",
    "#     imgs_array, labels_array = shuffle(imgs_array, labels_array, random_state=9)  \n",
    "    \n",
    "    return imgs_array, labels_array\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_module(x,\n",
    "                     filters_1x1,\n",
    "                     filters_3x3_reduce,\n",
    "                     filters_3x3,\n",
    "                     filters_5x5_reduce,\n",
    "                     filters_5x5,\n",
    "                     filters_pool_proj,\n",
    "                     name=None):\n",
    "    \n",
    "    conv_1x1 = Conv2D(filters_1x1, (1, 1), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(x)\n",
    "    \n",
    "    conv_3x3 = Conv2D(filters_3x3_reduce, (1, 1), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(x)\n",
    "    conv_3x3 = Conv2D(filters_3x3, (3, 3), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(conv_3x3)\n",
    "\n",
    "    conv_5x5 = Conv2D(filters_5x5_reduce, (1, 1), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(x)\n",
    "    conv_5x5 = Conv2D(filters_5x5, (5, 5), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(conv_5x5)\n",
    "\n",
    "    pool_proj = MaxPool2D((3, 3), strides=(1, 1), padding='same')(x)\n",
    "    pool_proj = Conv2D(filters_pool_proj, (1, 1), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(pool_proj)\n",
    "\n",
    "    output = concatenate([conv_1x1, conv_3x3, conv_5x5, pool_proj], axis=3, name=name)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputimg = keras.Input(shape=(96,96,1), name=\"original_img\")\n",
    "x = Conv2D(32, (3, 3), padding='same',  activation='relu', name='conv_1_3x3/1', kernel_initializer=kernel_init, bias_initializer=bias_init)(inputimg)\n",
    "x = MaxPool2D((3, 3), padding='same',  name='max_pool_1_3x3/2')(x)\n",
    "x = Conv2D(64, (1, 1), padding='same', strides=(1, 1), activation='relu', name='conv_2a_3x3/1')(x)\n",
    "x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_2_3x3/2')(x)\n",
    "x = Conv2D(128, (3, 3), padding='same', strides=(1, 1), activation='relu', name='conv_2b_3x3/1')(x)\n",
    "x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_3_3x3/2')(x)\n",
    "x=BatchNormalization()(x)\n",
    "\n",
    "x = inception_module(x,\n",
    "                     filters_1x1=64,\n",
    "                     filters_3x3_reduce=64,\n",
    "                     filters_3x3=128,\n",
    "                     filters_5x5_reduce=128,\n",
    "                     filters_5x5=246,\n",
    "                     filters_pool_proj=64,\n",
    "                     name='inception_3a')\n",
    "\n",
    "\n",
    "x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_4_3x3/2')(x)\n",
    "x=BatchNormalization()(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x = GlobalAveragePooling2D(name='avg_pool_5_3x3/1')(x)\n",
    "\n",
    "\n",
    "x = Dense(1024, activation='relu', name='dense_540')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(540, activation='relu', name='dense_540b')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(240, activation='relu', name='dense_240')(x)\n",
    "x = Dense(30, name='dense_30')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = keras.Model(inputimg, x, name='Gaurvendra_Singh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Gaurvendra_Singh\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "original_img (InputLayer)       (None, 96, 96, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_1_3x3/1 (Conv2D)           (None, 96, 96, 32)   320         original_img[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pool_1_3x3/2 (MaxPooling2D) (None, 32, 32, 32)   0           conv_1_3x3/1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_2a_3x3/1 (Conv2D)          (None, 32, 32, 64)   2112        max_pool_1_3x3/2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pool_2_3x3/2 (MaxPooling2D) (None, 16, 16, 64)   0           conv_2a_3x3/1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_2b_3x3/1 (Conv2D)          (None, 16, 16, 128)  73856       max_pool_2_3x3/2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pool_3_3x3/2 (MaxPooling2D) (None, 8, 8, 128)    0           conv_2b_3x3/1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 8, 8, 128)    512         max_pool_3_3x3/2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 8, 8, 64)     8256        batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 8, 8, 128)    16512       batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 128)    0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 8, 8, 64)     8256        batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 8, 8, 128)    73856       conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 8, 8, 246)    787446      conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 8, 8, 64)     8256        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a (Concatenate)      (None, 8, 8, 502)    0           conv2d_13[0][0]                  \n",
      "                                                                 conv2d_15[0][0]                  \n",
      "                                                                 conv2d_17[0][0]                  \n",
      "                                                                 conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pool_4_3x3/2 (MaxPooling2D) (None, 4, 4, 502)    0           inception_3a[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 4, 4, 502)    2008        max_pool_4_3x3/2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool_5_3x3/1 (GlobalAverage (None, 502)          0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_540 (Dense)               (None, 1024)         515072      avg_pool_5_3x3/1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 1024)         0           dense_540[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_540b (Dense)              (None, 540)          553500      dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 540)          0           dense_540b[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_240 (Dense)               (None, 240)          129840      dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 30)           7230        dense_240[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,187,032\n",
      "Trainable params: 2,185,772\n",
      "Non-trainable params: 1,260\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-2,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.9)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "Model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='mean_squared_error',\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training datapoint shape: X_train.shape:(2140, 96, 96, 1)\n",
      "Training labels shape: y_train.shape:(2140, 30)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = data_loader()\n",
    "print(\"Training datapoint shape: X_train.shape:{}\".format(X_train.shape))\n",
    "print(\"Training labels shape: y_train.shape:{}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1712 samples, validate on 428 samples\n",
      "Epoch 1/60\n",
      "1712/1712 [==============================] - 17s 10ms/step - loss: 1.1168 - accuracy: 0.4942 - val_loss: 21.4876 - val_accuracy: 0.4322\n",
      "Epoch 2/60\n",
      "1712/1712 [==============================] - 16s 10ms/step - loss: 0.0085 - accuracy: 0.7704 - val_loss: 1.7906 - val_accuracy: 0.4322\n",
      "Epoch 3/60\n",
      "1712/1712 [==============================] - 17s 10ms/step - loss: 0.0068 - accuracy: 0.7734 - val_loss: 0.0405 - val_accuracy: 0.4322\n",
      "Epoch 4/60\n",
      "1712/1712 [==============================] - 16s 9ms/step - loss: 0.0053 - accuracy: 0.7728 - val_loss: 0.0098 - val_accuracy: 0.4322\n",
      "Epoch 5/60\n",
      "1712/1712 [==============================] - 16s 9ms/step - loss: 0.0040 - accuracy: 0.7722 - val_loss: 0.0078 - val_accuracy: 0.4322\n",
      "Epoch 6/60\n",
      "1712/1712 [==============================] - 16s 9ms/step - loss: 0.0039 - accuracy: 0.7728 - val_loss: 0.0078 - val_accuracy: 0.4322\n",
      "Epoch 7/60\n",
      "1712/1712 [==============================] - 16s 10ms/step - loss: 0.0037 - accuracy: 0.7728 - val_loss: 0.0078 - val_accuracy: 0.4322\n",
      "Epoch 8/60\n",
      "1712/1712 [==============================] - 16s 9ms/step - loss: 0.0037 - accuracy: 0.7734 - val_loss: 0.0077 - val_accuracy: 0.4322\n",
      "Epoch 9/60\n",
      "1712/1712 [==============================] - 16s 9ms/step - loss: 0.0036 - accuracy: 0.7734 - val_loss: 0.0075 - val_accuracy: 0.4322\n",
      "Epoch 10/60\n",
      "1712/1712 [==============================] - 16s 9ms/step - loss: 0.0035 - accuracy: 0.7734 - val_loss: 0.0081 - val_accuracy: 0.4322\n",
      "Epoch 11/60\n",
      "1712/1712 [==============================] - 16s 9ms/step - loss: 0.0034 - accuracy: 0.7734 - val_loss: 0.0078 - val_accuracy: 0.4322\n",
      "Epoch 12/60\n",
      "1712/1712 [==============================] - 16s 10ms/step - loss: 0.0033 - accuracy: 0.7734 - val_loss: 0.0082 - val_accuracy: 0.4322\n",
      "Epoch 13/60\n",
      "1712/1712 [==============================] - 16s 10ms/step - loss: 0.0033 - accuracy: 0.7734 - val_loss: 0.0081 - val_accuracy: 0.4322\n",
      "Epoch 14/60\n",
      "1712/1712 [==============================] - 15s 9ms/step - loss: 0.0033 - accuracy: 0.7734 - val_loss: 0.0077 - val_accuracy: 0.4322\n",
      "Epoch 15/60\n",
      "1712/1712 [==============================] - 15s 9ms/step - loss: 0.0033 - accuracy: 0.7734 - val_loss: 0.0079 - val_accuracy: 0.4322\n",
      "Epoch 16/60\n",
      "1712/1712 [==============================] - 17s 10ms/step - loss: 0.0031 - accuracy: 0.7734 - val_loss: 0.0080 - val_accuracy: 0.4322\n",
      "Epoch 17/60\n",
      "1712/1712 [==============================] - 16s 9ms/step - loss: 0.0031 - accuracy: 0.7739 - val_loss: 0.0082 - val_accuracy: 0.4322\n",
      "Epoch 18/60\n",
      "1712/1712 [==============================] - 16s 9ms/step - loss: 0.0031 - accuracy: 0.7739 - val_loss: 0.0085 - val_accuracy: 0.4252\n",
      "Epoch 19/60\n",
      "1712/1712 [==============================] - 16s 9ms/step - loss: 0.0033 - accuracy: 0.7739 - val_loss: 0.0080 - val_accuracy: 0.4322\n",
      "Epoch 20/60\n",
      "1712/1712 [==============================] - 16s 10ms/step - loss: 0.0030 - accuracy: 0.7786 - val_loss: 0.0079 - val_accuracy: 0.4322\n",
      "Epoch 21/60\n",
      "1712/1712 [==============================] - 16s 10ms/step - loss: 0.0031 - accuracy: 0.7745 - val_loss: 0.0086 - val_accuracy: 0.3995\n",
      "Epoch 22/60\n",
      "1712/1712 [==============================] - 16s 9ms/step - loss: 0.0030 - accuracy: 0.7704 - val_loss: 0.0082 - val_accuracy: 0.4299\n",
      "Epoch 23/60\n",
      "1712/1712 [==============================] - 17s 10ms/step - loss: 0.0030 - accuracy: 0.7739 - val_loss: 0.0088 - val_accuracy: 0.4206\n",
      "Epoch 24/60\n",
      "1712/1712 [==============================] - 16s 9ms/step - loss: 0.0029 - accuracy: 0.7751 - val_loss: 0.0083 - val_accuracy: 0.4299\n",
      "Epoch 25/60\n",
      "1712/1712 [==============================] - 16s 9ms/step - loss: 0.0029 - accuracy: 0.7728 - val_loss: 0.0092 - val_accuracy: 0.4322\n",
      "Epoch 26/60\n",
      "1712/1712 [==============================] - 16s 10ms/step - loss: 0.0029 - accuracy: 0.7669 - val_loss: 0.0079 - val_accuracy: 0.4299\n",
      "Epoch 27/60\n",
      "1712/1712 [==============================] - 16s 9ms/step - loss: 0.0031 - accuracy: 0.7763 - val_loss: 0.0088 - val_accuracy: 0.4322\n",
      "Epoch 28/60\n",
      "1712/1712 [==============================] - 15s 9ms/step - loss: 0.0029 - accuracy: 0.7780 - val_loss: 0.0077 - val_accuracy: 0.4299\n",
      "Epoch 29/60\n",
      "1712/1712 [==============================] - 17s 10ms/step - loss: 0.0028 - accuracy: 0.7716 - val_loss: 0.0075 - val_accuracy: 0.4322\n",
      "Epoch 30/60\n",
      "1712/1712 [==============================] - 17s 10ms/step - loss: 0.0027 - accuracy: 0.7804 - val_loss: 0.0080 - val_accuracy: 0.4322\n",
      "Epoch 31/60\n",
      "1712/1712 [==============================] - 16s 9ms/step - loss: 0.0028 - accuracy: 0.7839 - val_loss: 0.0079 - val_accuracy: 0.4322\n",
      "Epoch 32/60\n",
      "1712/1712 [==============================] - 16s 10ms/step - loss: 0.0028 - accuracy: 0.7675 - val_loss: 0.0077 - val_accuracy: 0.4299\n",
      "Epoch 33/60\n",
      "1712/1712 [==============================] - 16s 10ms/step - loss: 0.0027 - accuracy: 0.7751 - val_loss: 0.0080 - val_accuracy: 0.4393\n",
      "Epoch 34/60\n",
      "1712/1712 [==============================] - 17s 10ms/step - loss: 0.0027 - accuracy: 0.7769 - val_loss: 0.0084 - val_accuracy: 0.4322\n",
      "Epoch 35/60\n",
      "1712/1712 [==============================] - 16s 9ms/step - loss: 0.0027 - accuracy: 0.7786 - val_loss: 0.0138 - val_accuracy: 0.4322\n",
      "Epoch 36/60\n",
      "1712/1712 [==============================] - 16s 10ms/step - loss: 0.0026 - accuracy: 0.7739 - val_loss: 0.0079 - val_accuracy: 0.4322\n",
      "Epoch 37/60\n",
      "1712/1712 [==============================] - 16s 9ms/step - loss: 0.0026 - accuracy: 0.7658 - val_loss: 0.0074 - val_accuracy: 0.4346\n",
      "Epoch 38/60\n",
      "1712/1712 [==============================] - 16s 9ms/step - loss: 0.0027 - accuracy: 0.7757 - val_loss: 0.0078 - val_accuracy: 0.4322\n",
      "Epoch 39/60\n",
      "1712/1712 [==============================] - 16s 9ms/step - loss: 0.0028 - accuracy: 0.7734 - val_loss: 0.0083 - val_accuracy: 0.4393\n",
      "Epoch 40/60\n",
      "1712/1712 [==============================] - 16s 9ms/step - loss: 0.0026 - accuracy: 0.7693 - val_loss: 0.0115 - val_accuracy: 0.4346\n",
      "Epoch 41/60\n",
      "1712/1712 [==============================] - 17s 10ms/step - loss: 0.0026 - accuracy: 0.7763 - val_loss: 0.0077 - val_accuracy: 0.4299\n",
      "Epoch 42/60\n",
      "1712/1712 [==============================] - 16s 10ms/step - loss: 0.0025 - accuracy: 0.7710 - val_loss: 0.0081 - val_accuracy: 0.4486\n",
      "Epoch 43/60\n",
      "1712/1712 [==============================] - 16s 9ms/step - loss: 0.0026 - accuracy: 0.7716 - val_loss: 0.0080 - val_accuracy: 0.4322\n",
      "Epoch 44/60\n",
      "1712/1712 [==============================] - 16s 9ms/step - loss: 0.0025 - accuracy: 0.7734 - val_loss: 0.0076 - val_accuracy: 0.4322\n",
      "Epoch 45/60\n",
      "1712/1712 [==============================] - 17s 10ms/step - loss: 0.0024 - accuracy: 0.7845 - val_loss: 0.0079 - val_accuracy: 0.4322\n",
      "Epoch 46/60\n",
      "1712/1712 [==============================] - 17s 10ms/step - loss: 0.0024 - accuracy: 0.7699 - val_loss: 0.0074 - val_accuracy: 0.4322\n",
      "Epoch 47/60\n",
      "1712/1712 [==============================] - 16s 10ms/step - loss: 0.0025 - accuracy: 0.7739 - val_loss: 0.0075 - val_accuracy: 0.4322\n",
      "Epoch 48/60\n",
      "1712/1712 [==============================] - 17s 10ms/step - loss: 0.0024 - accuracy: 0.7780 - val_loss: 0.0079 - val_accuracy: 0.4322\n",
      "Epoch 49/60\n",
      "1712/1712 [==============================] - 16s 9ms/step - loss: 0.0024 - accuracy: 0.7763 - val_loss: 0.0081 - val_accuracy: 0.4322\n",
      "Epoch 50/60\n",
      "1712/1712 [==============================] - 16s 9ms/step - loss: 0.0025 - accuracy: 0.7763 - val_loss: 0.0082 - val_accuracy: 0.4322\n",
      "Epoch 51/60\n",
      "1712/1712 [==============================] - 16s 9ms/step - loss: 0.0024 - accuracy: 0.7775 - val_loss: 0.0082 - val_accuracy: 0.4346\n",
      "Epoch 52/60\n",
      "1712/1712 [==============================] - 17s 10ms/step - loss: 0.0024 - accuracy: 0.7763 - val_loss: 0.0139 - val_accuracy: 0.4322\n",
      "Epoch 53/60\n",
      "1712/1712 [==============================] - 16s 9ms/step - loss: 0.0023 - accuracy: 0.7874 - val_loss: 0.0096 - val_accuracy: 0.4322\n",
      "Epoch 54/60\n",
      "1712/1712 [==============================] - 17s 10ms/step - loss: 0.0023 - accuracy: 0.7868 - val_loss: 0.0079 - val_accuracy: 0.4322\n",
      "Epoch 55/60\n",
      "1712/1712 [==============================] - 17s 10ms/step - loss: 0.0024 - accuracy: 0.7821 - val_loss: 0.0093 - val_accuracy: 0.4322\n",
      "Epoch 56/60\n",
      "1712/1712 [==============================] - 16s 10ms/step - loss: 0.0024 - accuracy: 0.7798 - val_loss: 0.0077 - val_accuracy: 0.4322\n",
      "Epoch 57/60\n",
      "1712/1712 [==============================] - 16s 10ms/step - loss: 0.0023 - accuracy: 0.7775 - val_loss: 0.0079 - val_accuracy: 0.4322\n",
      "Epoch 58/60\n",
      "1712/1712 [==============================] - 17s 10ms/step - loss: 0.0023 - accuracy: 0.7815 - val_loss: 0.0073 - val_accuracy: 0.4346\n",
      "Epoch 59/60\n",
      "1712/1712 [==============================] - 17s 10ms/step - loss: 0.0022 - accuracy: 0.7821 - val_loss: 0.0077 - val_accuracy: 0.4416\n",
      "Epoch 60/60\n",
      "1712/1712 [==============================] - 16s 9ms/step - loss: 0.0022 - accuracy: 0.7810 - val_loss: 0.0075 - val_accuracy: 0.4322\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2ae7b72a3c8>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model.fit(X_train, y_train, validation_split=0.2, epochs=60, batch_size=32, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\gaurvendra\\desktop\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\saving.py:165: UserWarning: TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "  'TensorFlow optimizers do not '\n"
     ]
    }
   ],
   "source": [
    "plt.plot(Model.history.history['accuracy'], label='train')\n",
    "plt.plot(Model.history.history['val_accuracy'], label='test')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "Model.save(\"face_keypoints.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('face_keypoints.h5')\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_points_main(img):\n",
    "\n",
    "    def detect_points(face_img):\n",
    "        me  = np.array(face_img)/255\n",
    "        x_test = np.expand_dims(me, axis=0)\n",
    "        x_test = np.expand_dims(x_test, axis=3)\n",
    "\n",
    "        y_test = model.predict(x_test)\n",
    "        label_points = (np.squeeze(y_test)*48)+48\n",
    "\n",
    "\n",
    "        return label_points\n",
    "\n",
    "    # load haarcascade\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "    dimensions = (96, 96)\n",
    "\n",
    "\n",
    "    try:\n",
    "        default_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        gray_img = cv2.cvtColor(default_img, cv2.COLOR_RGB2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray_img, 1.3, 5)\n",
    "#         faces = face_cascade.detectMultiScale(gray_img, 4, 6)\n",
    "\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "    faces_img = np.copy(gray_img)\n",
    "\n",
    "    plt.rcParams[\"axes.grid\"] = False\n",
    "\n",
    "\n",
    "    all_x_cords = []\n",
    "    all_y_cords = []\n",
    "\n",
    "\n",
    "    for i, (x,y,w,h) in enumerate(faces):\n",
    "\n",
    "        h += 10\n",
    "        w += 10\n",
    "        x -= 5\n",
    "        y -= 5\n",
    "\n",
    "        try:\n",
    "            just_face = cv2.resize(gray_img[y:y+h,x:x+w], dimensions)\n",
    "        except:\n",
    "            return []\n",
    "        cv2.rectangle(faces_img,(x,y),(x+w,y+h),(255,0,0),1)\n",
    "\n",
    "        scale_val_x = w/96\n",
    "        scale_val_y = h/96\n",
    "\n",
    "        label_point = detect_points(just_face)\n",
    "\n",
    "        all_x_cords.append((label_point[::2]*scale_val_x)+x)\n",
    "        all_y_cords.append((label_point[1::2]*scale_val_y)+y)\n",
    "\n",
    "\n",
    "\n",
    "    final_points_list = []\n",
    "    try:\n",
    "        for ii in range(len(all_x_cords)):\n",
    "            for a_x, a_y in zip(all_x_cords[ii], all_y_cords[ii]):\n",
    "                final_points_list.append([a_x, a_y])\n",
    "    except:\n",
    "        return final_points_list\n",
    "\n",
    "    return final_points_list\n",
    "\n",
    "# cap = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(\"https://192.168.43.1:8080/video\")\n",
    "ret, frame = cap.read()\n",
    "height, width, channel = frame.shape\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "out = cv2.VideoWriter(\"output_filename.avi\", fourcc, 20.0, (width, height))\n",
    "\n",
    "\n",
    "frame_no = 0\n",
    "while cap.isOpened():\n",
    "\n",
    "   \n",
    "    \n",
    "    frame_no += 1\n",
    "    ret, frame = cap.read()\n",
    "    if frame_no > 75*30:\n",
    "        break\n",
    "    if frame_no in range(60*30, 75*30):\n",
    "        points = get_points_main(frame)\n",
    "\n",
    "        try:\n",
    "            overlay = frame.copy()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            break\n",
    "\n",
    "        for point in points:\n",
    "\n",
    "            cv2.circle(frame, tuple(point), 3, (255, 255, 255), -1)\n",
    "            # cv2.line(frame, last_point, tuple(point), (0,0,255), thickness=1)\n",
    "            # cv2.putText(overlay, str(i), tuple(point), 1, 1, (255, 255, 255))\n",
    "\n",
    "        if len(points) != 0:\n",
    "            o_line_points = [[12,13], [13,11], [11,14], [14,12], [12,10], [11,10], [10,3], [12,5], [11,3], [10,5], [10,4], [10,2], [5,1], [1,4], [2,0], [0,3], [5,9], [9,8], [8,4], [2,6], [6,7], [7,3]]\n",
    "            num_face = len(points)//15\n",
    "\n",
    "            for i in range(num_face):\n",
    "                line_points = np.array(o_line_points) + (15*(i))\n",
    "\n",
    "                the_color = (189, 195, 199)\n",
    "\n",
    "                for ii in line_points:\n",
    "                    cv2.line(overlay, tuple(points[ii[0]]), tuple(points[ii[1]]), the_color, thickness=1)\n",
    "\n",
    "\n",
    "        opacity = 0.3\n",
    "        cv2.addWeighted(overlay, opacity, frame, 1 - opacity, 0, frame)\n",
    "\n",
    "        out.write(frame)\n",
    "        cv2.imshow('frame',frame)\n",
    "      \n",
    "        \n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
